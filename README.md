# âš›ï¸ Flux Time Series Prediction in Tokamak Reactors

![Python 3.13](https://img.shields.io/badge/python-3.13-blue?style=flat-square&logo=python&logoColor=white)
![UV](https://img.shields.io/pypi/v/uv?label=uv&style=flat-square&logo=pypi&logoColor=white)


Welcome to the Fusion Time Series playground â€” example code and notebooks for experimenting with flux time-series forecasting models and surrounding tooling.

## ğŸ§° Installation

See the [Installation Guide](docs/installation.md) for detailed setup instructions.

## ğŸ“š Documentation

```
docs/
â”œâ”€â”€ methods/
â”‚   â”œâ”€â”€ BilinearLoRA.md
â”‚   â”œâ”€â”€ OSSBilinearLoRA.md
â”‚   â””â”€â”€ RSSBilinearLoRA.md
â”œâ”€â”€ poster/
â”œâ”€â”€ report/
â”‚   â””â”€â”€ 0126-progress-report.md
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ finetuning/
â”‚   â”‚   â”œâ”€â”€ chronos2/
â”‚   â”‚   â””â”€â”€ timesfm/
â”‚   â””â”€â”€ zeroshot/
â””â”€â”€ installation.md
```

- **[methods/](docs/methods/)** - LoRA adaptation techniques documentation
- **[poster/](docs/poster/)** - Poster presentations
- **[report/](docs/report/)** - Progress reports and documentation
- **[results/](docs/results/)** - Experimental results
  - **[finetuning/](docs/results/finetuning/)** - Fine-tuning experiment results
  - **[zeroshot/](docs/results/zeroshot/)** - Zero-shot model results
- **[installation.md](docs/installation.md)** - Installation and setup guide

## ğŸ“Š Results

### Zero-Shot Results

| Base Model               | ID $\bar{Q}$ (â†“)  | OOD $\bar{Q}$     | Inference Time [s]  |
| ------------------------ | ----------------- | ----------------- | ------------------- |
| google/timesfm-2.0-500m  | 156.17 Â± 67.31    | 98.61 Â± 23.55     | 5.65 Â± 5.82e-2      |
| amazon/chronos-bolt-tiny | 110.15 Â± 14.08    | 92.89 Â± 21.16     | **0.030 Â± 1.08e-3** |
| amazon/chronos2          | 107.09 Â± 15.74    | 87.47 Â± 22.08     | 0.073 Â± 1.72e-3     |
| google/timesfm-2.5-200m  | 104.23 Â± 14.87    | 87.20 Â± 25.05     | 0.231 Â± 7.23e-3     |
| NX-AI/TiRex              | **79.49 Â± 14.38** | **64.03 Â± 19.53** | 1.95 Â± 1.63e-2      |

Zero-shot performance across five time-series foundation models.

### Finetuning Results


| Base Model                     | Finetuning Type  | ID $\bar{Q}$ (â†“) | OOD $\bar{Q}$   | Trainable Params (%) | Trainable Params (#Mio.) | Inference Time [s] |
| ------------------------------ | ---------------- | ---------------- | --------------- | -------------------- | ------------------------ | ------------------ |
| google/timesfm-2.0-500m        | Full Finetuning* | 20.67 Â± 7.43     | 12.01 Â± 3.21    | 100.0                | 498.8                    | 0.091 Â± 1.65e-3    |
| google/timesfm-2.0-500m        | BilinearLoRA     | 20.15 Â± 7.79     | 7.11 Â± 1.32     | 1.22                 | 6.2                      | 0.245 Â± 2.17e-3    |
| google/timesfm-2.0-500m        | OSSBilinearLoRA  | 19.24 Â± 7.87     | 7.74 Â± 2.08     | 28.91                | 202.8                    | 0.291 Â± 3.85e-3    |
| GyroSwin-1B [[1]](#references) | -                | 18.35 Â± 1.56     | 26.43 Â± 9.49    | 100.0                | 1000.0                   | 2.849**            |
| google/timesfm-2.0-500m        | RSSBilinearLoRA  | 18.03 Â± 6.81     | 7.86 Â± 2.20     | 1.39                 | 7.0                      | 0.304 Â± 2.50e-3    |
| google/timesfm-2.0-500m        | LoRA*            | 17.76 Â± 8.05     | 16.07 Â± 4.18    | 1.02                 | 5.1                      | 0.081 Â± 1.51e-3    |
| amazon/chronos2                | LoRA*            | 16.73 Â± 6.67     | 5.08 Â± 1.22     | 1.0                  | 1.2                      | 0.067 Â± 2.95e-2    |
| amazon/chronos2                | RSSBilinearLoRA  | 16.33 Â± 5.39     | 5.65 Â± 2.03     | 1.86                 | 2.3                      | 0.170 Â± 6.26e-3    |
| amazon/chronos2                | OSSBilinearLoRA  | 16.11 Â± 6.18     | **3.19 Â± 0.73** | 25.0                 | 39.8                     | 0.159 Â± 4.59e-3    |
| amazon/chronos2                | Full Finetuning* | 15.50 Â± 4.47     | 4.76 Â± 0.89     | 100.0                | 119.5                    | 0.050 Â± 7.07e-4    |
| amazon/chronos2                | BilinearLoRA     | **13.83 Â± 4.18** | 4.86 Â± 0.68     | 1.54                 | 1.9                      | 0.136 Â± 8.64e-4    |

- Comparison of finetuned performance across base models and GyroSwin
- For average heat flux $\bar{Q}$ we report RMSE of time-averaged predictions after an autoregressive rollout
- Time-series models are trained and benchmarked on a NVIDIA RTX 4070 16GB Ti Super
- (*) No operating parameter conditioning
- (**) To compare the inference speed to GyroSwin we use the reported 15.4ms forward pass inference speed and multiply by the number of rollout steps (185). The large speed gap can be mainly attributed to the fact that time-series models forecast 64 timesteps in one forward-pass. GyroSwin was benchmarked on a NVIDIA H100 80GB HBM3.

## References

```bibtex
@misc{paischer2025gyroswin5dsurrogatesgyrokinetic,
      title={GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations},
      author={Fabian Paischer and Gianluca Galletti and William Hornsby and Paul Setinek and Lorenzo Zanisi and Naomi Carey and Stanislas Pamela and Johannes Brandstetter},
      year={2025},
      eprint={2510.07314},
      archivePrefix={arXiv},
      primaryClass={physics.plasm-ph},
      url={https://arxiv.org/abs/2510.07314},
}
```
