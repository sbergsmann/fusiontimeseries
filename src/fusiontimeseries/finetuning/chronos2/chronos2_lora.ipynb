{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from fusiontimeseries.lib.get_next_path import get_next_path\n",
    "\n",
    "base_dir = Path(\"./results\")\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_dir = get_next_path(base_fname=\"chronos2-lora\", base_dir=base_dir)\n",
    "output_dir.mkdir(parents=True, exist_ok=False)\n",
    "print(f\"Output directory created at: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.lib.config import FTSConfig\n",
    "\n",
    "fts_config = FTSConfig(\n",
    "    op_embedding_dim=512,\n",
    "    num_ops=4,\n",
    "    context_length=512,\n",
    "    pred_tail_timestamps=80,\n",
    "    batch_size=128,\n",
    "    stratification_bins=5,\n",
    "    sampling_bins=5,\n",
    "    val_size=0.1,\n",
    "    padding_value=torch.nan,\n",
    "    padding_mask_default=0.0,\n",
    "    padding_mask_indicator=1.0,\n",
    "    stratification=\"opc_pca\",\n",
    "    sampling_strategy=\"linear\",\n",
    "    data_augmentation=\"white_noise\",\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    lr_scheduler_warmup_ratio=0.0,\n",
    "    optimizer_type=\"adamw_torch_fused\",\n",
    "    max_grad_norm=1.0,\n",
    "    max_steps=4000,\n",
    "    eval_steps=200,\n",
    "    gradient_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chronos import Chronos2Model\n",
    "\n",
    "model = Chronos2Model.from_pretrained(\"amazon/chronos-2\")\n",
    "model.chronos_config.context_length = fts_config.context_length\n",
    "model = model.to(fts_config.device)  # type: ignore\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.modules import ContinuousConditionEmbed\n",
    "\n",
    "shared_p_projection = ContinuousConditionEmbed(\n",
    "    embedding_dim=fts_config.op_embedding_dim,\n",
    "    n_cond=fts_config.num_ops,\n",
    "    max_wavelength=10_000,\n",
    "    init_weights=\"kaiming_uniform\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.loralib.layers import Linear\n",
    "\n",
    "\n",
    "model = Linear.convert(\n",
    "    module=model,\n",
    "    kind=\"LoRA\",\n",
    "    lora_rank=8,\n",
    "    lora_alpha=16,\n",
    "    target_module_names=[\n",
    "        \"self_attention.q\",\n",
    "        \"self_attention.k\",\n",
    "        \"self_attention.v\",\n",
    "        \"self_attention.o\",\n",
    "        \"output_patch_embedding.output_layer\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.loralib.utils import mark_only_lora_as_trainable\n",
    "\n",
    "\n",
    "mark_only_lora_as_trainable(model=model, bias=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.loralib.utils import print_trainable_parameters\n",
    "\n",
    "\n",
    "print_trainable_parameters(model, save_path=output_dir / \"trainable_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.finetuning.chronos2.dataset import Chronos2Dataset\n",
    "\n",
    "train_dataset, val_dataset = Chronos2Dataset.train_val_split(fts_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=str(output_dir),\n",
    "    per_device_train_batch_size=fts_config.batch_size,\n",
    "    per_device_eval_batch_size=fts_config.batch_size,\n",
    "    learning_rate=fts_config.learning_rate,\n",
    "    lr_scheduler_type=fts_config.lr_scheduler_type,\n",
    "    warmup_ratio=fts_config.lr_scheduler_warmup_ratio,\n",
    "    optim=fts_config.optimizer_type,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=fts_config.eval_steps,\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    max_steps=fts_config.max_steps,\n",
    "    gradient_accumulation_steps=fts_config.gradient_accumulation_steps,\n",
    "    dataloader_num_workers=0,\n",
    "    tf32=False,\n",
    "    bf16=False,\n",
    "    save_only_model=True,\n",
    "    prediction_loss_only=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=fts_config.eval_steps,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=fts_config.eval_steps,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    use_cpu=False,\n",
    "    label_names=[\"future_target\"],\n",
    "    remove_unused_columns=False,\n",
    "    max_grad_norm=fts_config.max_grad_norm,\n",
    ")\n",
    "training_arguments._n_gpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "from chronos.chronos2.model import Chronos2Model, Chronos2Output\n",
    "\n",
    "from fusiontimeseries.lib.conditioning import ConditionRegistry\n",
    "\n",
    "\n",
    "class ConditionedTrainer(Trainer):\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        model: Chronos2Model,\n",
    "        inputs: dict[str, torch.Tensor],\n",
    "        *args,\n",
    "        return_outputs=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Tensor[B, N]\n",
    "        p_raw: torch.Tensor | None = inputs.pop(\n",
    "            \"operating_parameters\", None\n",
    "        )  # remove before forward, otherwise TypeError in Trainer\n",
    "        assert p_raw is not None, \"operating_parameters key is missing in inputs\"\n",
    "\n",
    "        with ConditionRegistry.patch(op_params=p_raw):\n",
    "            outputs: Chronos2Output = model(**inputs)\n",
    "\n",
    "        loss = outputs.loss if hasattr(outputs, \"loss\") else outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "trainer = ConditionedTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "with open(output_dir / \"training_args.json\", \"w\") as f:\n",
    "    json.dump(trainer.args.to_dict(), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_output = trainer.train()\n",
    "\n",
    "with open(output_dir / \"train_summary.json\", \"w\") as f:\n",
    "    json.dump(train_output._asdict(), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.loralib.utils import lora_state_dict\n",
    "\n",
    "lora_weights = lora_state_dict(model)\n",
    "torch.save(lora_weights, output_dir / \"lora_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_data = Chronos2Dataset.get_benchmark_flux_traces(fts_config)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.lib.benchmarking import rmse_with_standard_error\n",
    "from fusiontimeseries.lib.dataset import FluxData\n",
    "import numpy as np\n",
    "\n",
    "START_IDX: int = 80\n",
    "\n",
    "id_benchmark_data = benchmark_data[\"id\"]\n",
    "id_benchmark_forecasts: dict[int, list[float]] = {}\n",
    "for flux_id, flux_data in id_benchmark_data.items():\n",
    "    flux_data: FluxData\n",
    "    energy_flux = np.array(flux_data.energy_flux)\n",
    "    op_params = (\n",
    "        torch.Tensor(flux_data.operating_parameters).unsqueeze(0).to(fts_config.device)\n",
    "    )\n",
    "\n",
    "    ctx: np.ndarray = energy_flux[:START_IDX]\n",
    "    while len(ctx) < len(energy_flux):\n",
    "        with torch.no_grad():\n",
    "            tctx = torch.full(\n",
    "                size=(1, fts_config.context_length), fill_value=fts_config.padding_value\n",
    "            )  # NaN\n",
    "            tctx[0, -len(ctx) :] = torch.tensor(ctx)\n",
    "            context_mask = torch.full_like(\n",
    "                tctx, fill_value=fts_config.padding_mask_default\n",
    "            )  # 0.0\n",
    "            context_mask[0, -len(ctx) :] = fts_config.padding_mask_indicator  # 1.0\n",
    "\n",
    "            with ConditionRegistry.patch(op_params=op_params):\n",
    "                output: Chronos2Output = model(\n",
    "                    context=tctx.to(fts_config.device),\n",
    "                    context_mask=context_mask.to(fts_config.device),\n",
    "                )\n",
    "        if output.quantile_preds is not None:\n",
    "            quantiles: torch.Tensor = output.quantile_preds  # (B, Qs=21, pred_len)\n",
    "            median_quantile: int = quantiles.shape[1] // 2\n",
    "            forecast: np.ndarray = (\n",
    "                quantiles[:, median_quantile, :].cpu().numpy().flatten()\n",
    "            )  # (pred_len,)\n",
    "            ctx = np.concatenate([ctx, forecast])\n",
    "\n",
    "    id_benchmark_forecasts[flux_id] = ctx[\n",
    "        : len(energy_flux)\n",
    "    ].tolist()  # Trim to original length\n",
    "\n",
    "\n",
    "id_benchmark_means: list[np.floating] = [\n",
    "    np.mean(flux_data.energy_flux[:-80]) for _id, flux_data in id_benchmark_data.items()\n",
    "]\n",
    "id_forecast_means: list[np.floating] = [\n",
    "    np.mean(forecast[:-80]) for forecast in id_benchmark_forecasts.values()\n",
    "]\n",
    "id_rmse, id_rmse_se = rmse_with_standard_error(\n",
    "    y_true=np.array(id_benchmark_means), y_pred=np.array(id_forecast_means)\n",
    ")\n",
    "id_rmse, id_rmse_se, id_benchmark_means, id_forecast_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_benchmark_data = benchmark_data[\"ood\"]\n",
    "ood_benchmark_forecasts: dict[int, list[float]] = {}\n",
    "for flux_id, flux_data in ood_benchmark_data.items():\n",
    "    flux_data: FluxData\n",
    "    energy_flux = np.array(flux_data.energy_flux)\n",
    "    op_params = (\n",
    "        torch.Tensor(flux_data.operating_parameters).unsqueeze(0).to(fts_config.device)\n",
    "    )\n",
    "\n",
    "    ctx: np.ndarray = energy_flux[:START_IDX]\n",
    "    while len(ctx) < len(energy_flux):\n",
    "        with torch.no_grad():\n",
    "            tctx = torch.full(\n",
    "                size=(1, fts_config.context_length), fill_value=fts_config.padding_value\n",
    "            )  # NaN\n",
    "            tctx[0, -len(ctx) :] = torch.tensor(ctx)\n",
    "            context_mask = torch.full_like(\n",
    "                tctx, fill_value=fts_config.padding_mask_default\n",
    "            )  # 0.0\n",
    "            context_mask[0, -len(ctx) :] = fts_config.padding_mask_indicator  # 1.0\n",
    "\n",
    "            with ConditionRegistry.patch(op_params=op_params):\n",
    "                output: Chronos2Output = model(\n",
    "                    context=tctx.to(fts_config.device),\n",
    "                    context_mask=context_mask.to(fts_config.device),\n",
    "                )\n",
    "        if output.quantile_preds is not None:\n",
    "            quantiles: torch.Tensor = output.quantile_preds  # (B, Qs=21, pred_len)\n",
    "            median_quantile: int = quantiles.shape[1] // 2\n",
    "            forecast: np.ndarray = (\n",
    "                quantiles[:, median_quantile, :].cpu().numpy().flatten()\n",
    "            )  # (pred_len,)\n",
    "            ctx = np.concatenate([ctx, forecast])\n",
    "\n",
    "    ood_benchmark_forecasts[flux_id] = ctx[\n",
    "        : len(energy_flux)\n",
    "    ].tolist()  # Trim to original length\n",
    "\n",
    "ood_benchmark_means: list[np.floating] = [\n",
    "    np.mean(flux_data.energy_flux[:-80])\n",
    "    for _id, flux_data in ood_benchmark_data.items()\n",
    "]\n",
    "ood_forecast_means: list[np.floating] = [\n",
    "    np.mean(forecast[:-80]) for forecast in ood_benchmark_forecasts.values()\n",
    "]\n",
    "ood_rmse, ood_rmse_se = rmse_with_standard_error(\n",
    "    y_true=np.array(ood_benchmark_means), y_pred=np.array(ood_forecast_means)\n",
    ")\n",
    "ood_rmse, ood_rmse_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save forecast means for each time series id and the total rmse and standard error for id and ood to the load_dir in a json file\n",
    "import json\n",
    "\n",
    "results = {\n",
    "    \"metrics\": {\n",
    "        \"id\": {\n",
    "            \"rmse\": float(id_rmse),\n",
    "            \"standard_error\": float(id_rmse_se),\n",
    "        },\n",
    "        \"ood\": {\n",
    "            \"rmse\": float(ood_rmse),\n",
    "            \"standard_error\": float(ood_rmse_se),\n",
    "        },\n",
    "    },\n",
    "    \"forecasts\": {\n",
    "        \"id\": {**id_benchmark_forecasts},\n",
    "        \"ood\": {**ood_benchmark_forecasts},\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(output_dir / \"benchmark_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(3 * 3, 2 * 2), sharex=\"col\")\n",
    "axes = axes.flatten()\n",
    "for ax_id, flux_id in enumerate(id_benchmark_data.keys()):\n",
    "    ax = axes[ax_id]\n",
    "    flux_data = id_benchmark_data[flux_id]\n",
    "    energy_flux = np.array(flux_data.energy_flux)\n",
    "\n",
    "    ax.plot(energy_flux)\n",
    "    ax.plot(id_benchmark_forecasts[flux_id])\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        0.9,\n",
    "        f\"OPs: {flux_data.operating_parameters}\",\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=7,\n",
    "    )\n",
    "    ax.set_title(f\"Flux ID: {flux_id}\", fontdict={\"fontsize\": 5})\n",
    "    ax.set_xlabel(\"Time Step\", fontdict={\"fontsize\": 5})\n",
    "    ax.set_ylabel(\"Energy Flux\", fontdict={\"fontsize\": 5})\n",
    "fig.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(3 * 3, 2 * 2), sharex=\"col\")\n",
    "axes = axes.flatten()\n",
    "for ax_id, flux_id in enumerate(ood_benchmark_data.keys()):\n",
    "    ax = axes[ax_id]\n",
    "    flux_data = ood_benchmark_data[flux_id]\n",
    "    energy_flux = np.array(flux_data.energy_flux)\n",
    "\n",
    "    ax.plot(energy_flux)\n",
    "    ax.plot(ood_benchmark_forecasts[flux_id])\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        0.9,\n",
    "        f\"OPs: {flux_data.operating_parameters}\",\n",
    "        horizontalalignment=\"center\",\n",
    "        verticalalignment=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=7,\n",
    "    )\n",
    "    ax.set_title(f\"Flux ID: {flux_id}\", fontdict={\"fontsize\": 5})\n",
    "    ax.set_xlabel(\"Time Step\", fontdict={\"fontsize\": 5})\n",
    "    ax.set_ylabel(\"Energy Flux\", fontdict={\"fontsize\": 5})\n",
    "fig.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusiontimeseries (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
