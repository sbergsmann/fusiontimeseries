{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.torch import DeepAREstimator\n",
    "import numpy as np\n",
    "from fusiontimeseries.finetuning.preprocessing.utils import get_valid_flux_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "flux_data: dict[int, np.ndarray] = get_valid_flux_traces()\n",
    "\n",
    "id_records = []\n",
    "for item_id, flux_trace in flux_data.items():\n",
    "    for t in range(flux_trace.shape[0]):\n",
    "        id_records.append(\n",
    "            {\n",
    "                \"item_id\": item_id,\n",
    "                \"time_idx\": t,\n",
    "                \"target\": flux_trace[t],\n",
    "            }\n",
    "        )\n",
    "df = pd.DataFrame(id_records)\n",
    "\n",
    "df = df.sort_values([\"item_id\", \"time_idx\"])\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(datetime(2000, 1, 1)) + pd.to_timedelta(\n",
    "    df[\"time_idx\"], unit=\"h\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PandasDataset.from_long_dataframe(\n",
    "    df,\n",
    "    item_id=\"item_id\",\n",
    "    timestamp=\"timestamp\",\n",
    "    target=\"target\",\n",
    "    freq=\"h\",  # frequency of the generated time index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from gluonts.dataset.split import (\n",
    "    AbstractBaseSplitter,\n",
    "    TrainingDataset,\n",
    "    DataEntry,\n",
    "    slice_data_entry,\n",
    "    FieldName,\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DummySplitter(AbstractBaseSplitter):\n",
    "    \"\"\"\n",
    "    A dummy splitter that does not acutally split but is required to create a TrainingDataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def training_entry(self, entry: DataEntry) -> DataEntry:\n",
    "        return entry\n",
    "\n",
    "    def test_pair(\n",
    "        self, entry: DataEntry, prediction_length: int, offset: int = 0\n",
    "    ) -> tuple[DataEntry, DataEntry]:\n",
    "        input_slice = slice(\n",
    "            0, len(entry[FieldName.TARGET]) - offset - prediction_length\n",
    "        )\n",
    "        label_slice = slice(\n",
    "            len(entry[FieldName.TARGET]) - offset - prediction_length,\n",
    "            len(entry[FieldName.TARGET]) - offset,\n",
    "        )\n",
    "        print(f\"input_slice: {input_slice}, label_slice: {label_slice}\")\n",
    "        return (\n",
    "            slice_data_entry(entry, input_slice, prediction_length=prediction_length),\n",
    "            slice_data_entry(entry, label_slice, prediction_length=prediction_length),\n",
    "        )\n",
    "\n",
    "\n",
    "training_data = TrainingDataset(dataset=dataset, splitter=DummySplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_LENGTH = 266 - 80  # tail of 80ÃŸ time steps is used in benchmark as well\n",
    "\n",
    "# Train the model and make predictions\n",
    "model = DeepAREstimator(\n",
    "    prediction_length=PREDICTION_LENGTH, freq=\"h\", trainer_kwargs={\"max_epochs\": 20}\n",
    ").train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch import Tensor\n",
    "from gluonts.dataset.split import TestTemplate\n",
    "\n",
    "from fusiontimeseries.benchmarking.benchmark_utils import (\n",
    "    BenchmarkDataProvider,\n",
    "    IN_DISTRIBUTION_ITERATIONS,\n",
    "    OUT_OF_DISTRIBUTION_ITERATIONS,\n",
    ")\n",
    "\n",
    "benchmark_data = BenchmarkDataProvider()\n",
    "\n",
    "id_records: list[dict[str, Any]] = []\n",
    "for item_id, iteration in enumerate(IN_DISTRIBUTION_ITERATIONS):\n",
    "    id_iteration: Tensor = benchmark_data.get_id(iteration)\n",
    "    for t in range(id_iteration.shape[0]):\n",
    "        id_records.append(\n",
    "            {\n",
    "                \"timestamp\": pd.to_datetime(datetime(2000, 1, 1))\n",
    "                + pd.to_timedelta(t, unit=\"h\"),\n",
    "                \"item_id\": item_id,\n",
    "                \"target\": id_iteration[t].item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "id_benchmark_dataset = PandasDataset.from_long_dataframe(\n",
    "    pd.DataFrame(id_records),\n",
    "    item_id=\"item_id\",\n",
    "    timestamp=\"timestamp\",\n",
    "    target=\"target\",\n",
    "    freq=\"h\",  # frequency of the generated time index\n",
    ")\n",
    "id_benchmark_set = TestTemplate(\n",
    "    id_benchmark_dataset, DummySplitter()\n",
    ").generate_instances(prediction_length=PREDICTION_LENGTH, windows=1)\n",
    "\n",
    "ood_records: list[dict[str, Any]] = []\n",
    "for item_id, iteration in enumerate(OUT_OF_DISTRIBUTION_ITERATIONS):\n",
    "    id_iteration: Tensor = benchmark_data.get_ood(iteration)\n",
    "    for t in range(id_iteration.shape[0]):\n",
    "        ood_records.append(\n",
    "            {\n",
    "                \"timestamp\": pd.to_datetime(datetime(2000, 1, 1))\n",
    "                + pd.to_timedelta(t, unit=\"h\"),\n",
    "                \"item_id\": item_id,\n",
    "                \"target\": id_iteration[t].item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "ood_benchmark_dataset = PandasDataset.from_long_dataframe(\n",
    "    pd.DataFrame(ood_records),\n",
    "    item_id=\"item_id\",\n",
    "    timestamp=\"timestamp\",\n",
    "    target=\"target\",\n",
    "    freq=\"h\",  # frequency of the generated time index\n",
    ")\n",
    "ood_benchmark_set = TestTemplate(\n",
    "    ood_benchmark_dataset, DummySplitter()\n",
    ").generate_instances(prediction_length=PREDICTION_LENGTH, windows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_forecasts = list(model.predict(id_benchmark_set.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_forecasts[0].samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "id_df = pd.DataFrame(id_records)\n",
    "id_df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "for forecast in id_forecasts:\n",
    "    forecast.plot()\n",
    "    id_df[id_df[\"item_id\"] == int(forecast.item_id)][\"target\"].plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_forecasts = list(model.predict(ood_benchmark_set.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df = pd.DataFrame(ood_records)\n",
    "ood_df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "for forecast in ood_forecasts:\n",
    "    forecast.plot()\n",
    "    ood_df[ood_df[\"item_id\"] == int(forecast.item_id)][\"target\"].plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Autoregressive Forecasting\n",
    "\n",
    "Train with a smaller prediction horizon (e.g., 20 steps) and then perform autoregressive forecasting to reach the full 186-step benchmark horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with a smaller prediction horizon\n",
    "TRAIN_PREDICTION_LENGTH = 44  # Smaller horizon for training\n",
    "BENCHMARK_PREDICTION_LENGTH = 266 - 80  # Full benchmark horizon (186 steps)\n",
    "\n",
    "# Train the model with smaller prediction length\n",
    "autoregressive_model = DeepAREstimator(\n",
    "    prediction_length=TRAIN_PREDICTION_LENGTH,\n",
    "    freq=\"h\",\n",
    "    hidden_size=64,\n",
    "    num_layers=4,\n",
    "    trainer_kwargs={\"max_epochs\": 32},\n",
    ").train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model.forecast import SampleForecast\n",
    "\n",
    "\n",
    "def autoregressive_forecast(model, input_data, total_steps, step_size):\n",
    "    \"\"\"\n",
    "    Perform autoregressive forecasting by iteratively predicting and appending results.\n",
    "\n",
    "    Args:\n",
    "        model: Trained GluonTS model\n",
    "        input_data: Initial input data entry\n",
    "        total_steps: Total number of steps to forecast\n",
    "        step_size: Number of steps to predict in each iteration (model's prediction_length)\n",
    "\n",
    "    Returns:\n",
    "        Array of shape (num_samples, total_steps) with forecasted values\n",
    "    \"\"\"\n",
    "    all_samples = []\n",
    "    current_data = dict(input_data)\n",
    "    remaining_steps = total_steps\n",
    "\n",
    "    while remaining_steps > 0:\n",
    "        steps_to_predict = min(step_size, remaining_steps)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = next(iter(model.predict([current_data])))\n",
    "\n",
    "        # Get samples: shape (num_samples, prediction_length)\n",
    "        samples = forecast.samples\n",
    "\n",
    "        # Take only the required number of steps\n",
    "        if steps_to_predict < step_size:\n",
    "            samples = samples[:, :steps_to_predict]\n",
    "\n",
    "        all_samples.append(samples)\n",
    "\n",
    "        # Update for next iteration: append mean prediction to target\n",
    "        mean_prediction = samples.mean(axis=0)\n",
    "        current_data[FieldName.TARGET] = np.concatenate(\n",
    "            [current_data[FieldName.TARGET], mean_prediction]\n",
    "        )\n",
    "\n",
    "        # Update start timestamp\n",
    "        if FieldName.START in current_data:\n",
    "            current_data[FieldName.START] = (\n",
    "                current_data[FieldName.START] + steps_to_predict\n",
    "            )\n",
    "\n",
    "        remaining_steps -= steps_to_predict\n",
    "\n",
    "    # Concatenate all samples along time dimension\n",
    "    all_samples_array = np.concatenate(all_samples, axis=1)\n",
    "\n",
    "    return all_samples_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform autoregressive forecasting on ID benchmark data\n",
    "id_autoregressive_forecasts = []\n",
    "\n",
    "for input_data, label_data in id_benchmark_set:\n",
    "    samples = autoregressive_forecast(\n",
    "        autoregressive_model,\n",
    "        input_data,\n",
    "        total_steps=BENCHMARK_PREDICTION_LENGTH,\n",
    "        step_size=TRAIN_PREDICTION_LENGTH,\n",
    "    )\n",
    "\n",
    "    # Create a SampleForecast object for compatibility with existing code\n",
    "    forecast = SampleForecast(\n",
    "        samples=samples,\n",
    "        start_date=label_data[FieldName.START],\n",
    "        item_id=input_data.get(\"item_id\", None),\n",
    "    )\n",
    "    id_autoregressive_forecasts.append(forecast)\n",
    "\n",
    "print(f\"Generated {len(id_autoregressive_forecasts)} autoregressive forecasts\")\n",
    "print(f\"First forecast shape: {id_autoregressive_forecasts[0].samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize autoregressive forecasts for ID data\n",
    "for forecast in id_autoregressive_forecasts:\n",
    "    forecast.plot()\n",
    "    id_df[id_df[\"item_id\"] == int(forecast.item_id)][\"target\"].plot()\n",
    "    plt.title(f\"Autoregressive Forecast - ID Item {forecast.item_id}\")\n",
    "    plt.legend([\"Forecast (median)\", \"Prediction intervals\", \"Actual\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform autoregressive forecasting on OOD benchmark data\n",
    "ood_autoregressive_forecasts = []\n",
    "\n",
    "for input_data, label_data in ood_benchmark_set:\n",
    "    samples = autoregressive_forecast(\n",
    "        autoregressive_model,\n",
    "        input_data,\n",
    "        total_steps=BENCHMARK_PREDICTION_LENGTH,\n",
    "        step_size=TRAIN_PREDICTION_LENGTH,\n",
    "    )\n",
    "\n",
    "    forecast = SampleForecast(\n",
    "        samples=samples,\n",
    "        start_date=label_data[FieldName.START],\n",
    "        item_id=input_data.get(\"item_id\", None),\n",
    "    )\n",
    "    ood_autoregressive_forecasts.append(forecast)\n",
    "\n",
    "print(f\"Generated {len(ood_autoregressive_forecasts)} OOD autoregressive forecasts\")\n",
    "print(f\"First forecast shape: {ood_autoregressive_forecasts[0].samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize autoregressive forecasts for OOD data\n",
    "for forecast in ood_autoregressive_forecasts:\n",
    "    forecast.plot()\n",
    "    ood_df[ood_df[\"item_id\"] == int(forecast.item_id)][\"target\"].plot()\n",
    "    plt.title(f\"Autoregressive Forecast - OOD Item {forecast.item_id}\")\n",
    "    plt.legend([\"Forecast (median)\", \"Prediction intervals\", \"Actual\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusiontimeseries (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
