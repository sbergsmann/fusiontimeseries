{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from chronos import Chronos2Pipeline\n",
    "from fusiontimeseries.lib.config import FTSConfig\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "fts_config = FTSConfig()\n",
    "fts_config.prediction_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_slug = \"amazon/chronos-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline: Chronos2Pipeline = Chronos2Pipeline.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_slug,\n",
    "    device_map=fts_config.device,\n",
    "    dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusiontimeseries.lib.dataset import TimeseriesDataset\n",
    "\n",
    "benchmark_flux_traces = TimeseriesDataset.get_benchmark_flux_traces(config=fts_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "START_TIMESTAMP: int = 80\n",
    "forecasts: dict[Literal[\"id\", \"ood\"], dict[int, np.ndarray]] = {\n",
    "    \"id\": {},\n",
    "    \"ood\": {},\n",
    "}\n",
    "\n",
    "for distribution, samples in benchmark_flux_traces.items():\n",
    "    for sample_id, flux_trace in samples.items():\n",
    "        time_series: np.ndarray = np.array(flux_trace.energy_flux)\n",
    "\n",
    "        ctx = torch.tensor(time_series[:START_TIMESTAMP], dtype=torch.float32)\n",
    "\n",
    "        while len(ctx) < len(time_series):\n",
    "            # quantile_outputs: list(n_variates, n_quantiles, prediction_length)\n",
    "            quantile_outputs: list[torch.Tensor] = pipeline.predict(\n",
    "                # inputs: (n_series, n_variates, context_length)\n",
    "                inputs=ctx.unsqueeze(0).unsqueeze(0),\n",
    "                prediction_length=fts_config.prediction_length,\n",
    "            )\n",
    "            quantiles: torch.Tensor = quantile_outputs[0]\n",
    "\n",
    "            median_quantile_idx: int = quantiles.shape[1] // 2\n",
    "            median_forecast: torch.Tensor = quantiles[0, median_quantile_idx, :].cpu()\n",
    "\n",
    "            ctx = torch.cat((ctx, median_forecast), dim=0)\n",
    "\n",
    "        forecast: np.ndarray = ctx[: len(time_series)].numpy()\n",
    "        forecasts[distribution][sample_id] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from fusiontimeseries.benchmarking.benchmark_utils import rmse_with_standard_error\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results: dict[str, dict[Literal[\"rsme\", \"rsme_se\"], float]] | str = {\n",
    "    \"id\": {},\n",
    "    \"ood\": {},\n",
    "    \"timestamp\": timestamp,\n",
    "    \"prediction_length\": fts_config.prediction_length,\n",
    "}  # type: ignore\n",
    "\n",
    "for distribution, samples in benchmark_flux_traces.items():\n",
    "    y_true: list[float] = []\n",
    "    y_pred: list[float] = []\n",
    "\n",
    "    for sample_id, flux_trace in samples.items():\n",
    "        time_series: np.ndarray = np.array(flux_trace.energy_flux)\n",
    "        target_mean = time_series[-fts_config.pred_tail_timestamps :].mean()\n",
    "        forecast_mean = forecasts[distribution][sample_id][\n",
    "            -fts_config.pred_tail_timestamps :\n",
    "        ].mean()\n",
    "        y_true.append(target_mean)\n",
    "        y_pred.append(forecast_mean)\n",
    "\n",
    "    rsme, rsme_se = rmse_with_standard_error(np.array(y_true), np.array(y_pred))\n",
    "    results[distribution][\"rsme\"] = rsme  # type: ignore\n",
    "    results[distribution][\"rsme_se\"] = rsme_se  # type: ignore\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Prepare results\n",
    "model_name_clean = model_slug.replace(\"/\", \"_\")\n",
    "\n",
    "# Save results to JSON\n",
    "data_dir = Path(\".\").resolve() / \"results\" / model_name_clean\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_file = data_dir / f\"{timestamp}_{model_name_clean}_benchmark_results.json\"\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save plots of forecasts vs true values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_dir = data_dir / \"plots\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "for distribution, samples in benchmark_flux_traces.items():\n",
    "    for sample_id, flux_trace in samples.items():\n",
    "        time_series: np.ndarray = np.array(flux_trace.energy_flux)\n",
    "        forecast: np.ndarray = forecasts[distribution][sample_id]\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(time_series, label=\"True Values\")\n",
    "        plt.plot(forecast, label=\"Forecast\", linestyle=\"--\")\n",
    "        plt.title(\n",
    "            f\"Forecast vs True Values ({distribution.upper()}) - Sample {sample_id}\"\n",
    "        )\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Energy Flux\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plot_file = (\n",
    "            plot_dir\n",
    "            / f\"{timestamp}_{model_name_clean}_{distribution}_sample_{sample_id}_forecast.png\"\n",
    "        )\n",
    "        plt.savefig(plot_file)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusiontimeseries (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
